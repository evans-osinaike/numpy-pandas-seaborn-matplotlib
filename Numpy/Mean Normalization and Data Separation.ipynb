{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001, (1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print('The shape of X is:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis = 0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols =X.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of ave_cols:  (20,)\n",
      "shape of std_cols:  (20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print('shape of ave_cols: ', ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print('shape of std_cols: ', std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average of all the values of X_norm:  -4.973799150320701e-18\n",
      "the average of the minimum value in each column of X_norm:  -1.7231562671775147\n",
      "the average of the maximum value in each column of X_norm:  1.7338353663359396\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print('the average of all the values of X_norm: ', X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print('the average of the minimum value in each column of X_norm: ', np.mean(X_norm.min(axis = 0)))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print('the average of the maximum value in each column of X_norm: ', np.mean(X_norm.max(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 0, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[545 383 821 451 651 682 248 534 765   3 228 220 877 929 810 967 666  20\n",
      " 590 775 234 309 398  98 687 787 707 186 457 310 507 767 783 846 746 555\n",
      " 261 281 106 180 830 675 845 484 119 576 745 776 209 668 152 873 722 644\n",
      " 586 988 955 641 488 514 173 147 535 270 925 860 995 448 566 377 482 645\n",
      " 606 504 201  96 372  24 290 197 471 603  15 677 153 853  83 540 811 543\n",
      " 171  75 891 994 479 244 868 191  72 295 263 536 189  78 472 505 871 986\n",
      " 266 272 964 667 340  77 961 734 382 205 331 541 890 742 408 417  46 990\n",
      " 373 601 304 181 771 938 844 549 175 144 286 869 416 717 150 529 676 256\n",
      " 112  13 605 172 393 154 425 170  44 284  37 239 133 251 739 438  22 554\n",
      " 314 432 352 626 370 945 597 206 267 233 303 843 325 463 280 296 396 257\n",
      " 607 495 376 743 560 604 149 744 260 518 158 737 477 820  87  32 798 575\n",
      " 496 610 824 656 801 705 959 519 350 127  82 223 588 720 570 243 764  91\n",
      " 971 640 692 714 100 391 685 375 620  85 833 160  54 358 405 761 508 673\n",
      " 523 353 434 987 458 333 951 318 436 182  66 953 629 663 556   7 470 805\n",
      " 633 360 113 627 635 751 658 558 512 317 315 492 262 207 969 443 781 901\n",
      " 403 976 232 312 528 686 862 616 327 481  89  65  69 619 797  94 101 369\n",
      " 423 347 680 473 825 834 249 330  53 823 928 568 527 989 526 441  35 424\n",
      " 275 836 102 215 517 726 856 691 326 612 593 789 643  43 914 283  31 433\n",
      " 730 509  70 758 125 879 444 307 716 584 521 214 361 348 719 456 240 245\n",
      " 452 747 439  11 662 898  19 793 225 581 865 571 996 915 778 741 530 621\n",
      "  14 683 926 609 580 905 611  28 371 297 474 276 415  52 413 367 952 883\n",
      " 342 157 792 237 210 531 196 689 822 183 395  93 878 305 779 932 217 709\n",
      " 906  29 109 221  45 219 618 773 167 977 349 723 467 374 669 916 672 882\n",
      " 649 117 146 300 638 867  62  17 812 108 650 736  64   0 934 422 884 562\n",
      " 293 583 591 345 636  25 242 818 579 174 782 168 476 406  33 419 738 252\n",
      " 493 394 946 569 176 874 247 708 835 131 241 486  68 596 774 447 615 599\n",
      " 294 710 388 487 678 795 997 264  42 937 904 399 185 902 250 292 155 598\n",
      " 796 278 291 357 516 702 956 624 772 311 642 366 469 991 500  90 387 563\n",
      "  39 138 218 785 718 582  41 338 460 748 442  49 777 381 786  84 721 364\n",
      " 962 195 919  23 698 344 258 935 134 179 999 647 574  55 625 794 552 911\n",
      " 355  97 918  59   9  95  74 397 483 450 111 930   6 655 329 791 238 639\n",
      "  47 917 849 501 931 203 515 750 506 105 421 298 974 939 940 875 494 414\n",
      " 960 222 983 975 957 770 950 107 817  30  58 841 564 445 135 335 211 230\n",
      " 498 880 462 752 359 587 216 712 389 362 694 724 503 551 788 684 592  79\n",
      " 696 165 790 502 490 695 392 316 886 274 948 920 648 896 513 826 449  63\n",
      " 903 700 255 978 966 847 585 324 378   2 226 202 893 151 561 646 302 814\n",
      " 385 657 246 887 829 653 728 141 198 690 103 455 491 465 430 231 435 806\n",
      " 363 912 411 356 740 763 589 213 162 188   4   5 271 323  71 981  56 269\n",
      "  34 733 328 124  99 908 732 759 177 118 933 769 922 895 681 577 166  21\n",
      " 163 145 949 713 354 178 461 715 832 665 525 727 613 693 337 546  10 768\n",
      " 140 889 410 831 156 308 332 289 697 923 699 760 212 857 190 524 936 809\n",
      " 664 224 970 711  40 336 659 838  27 510 114 852 559 565 804 236 963 299\n",
      " 539  81 380 365 839 132  60 402 909 828 123 522  61 285 755 614 654 992\n",
      " 842 802 731 859 553 924 854 351 139 159 468 631 827 204 881  86 277 128\n",
      " 320 459 319 557 637 808 208 567 437 947 973  76 858 404 464 670 110 229\n",
      "  48 466 628 980 129 227 652 547  88 485 813 313 706 780 187 894 900 942\n",
      " 799 876 573 288  38 851 379 892 866 757 979 819  73 265 321 386 478 428\n",
      " 701 572 480 184 121 870 148 800  26 401 594 921 400 863 850 679 864 623\n",
      " 634 368 807 429 855   8 287 511 725 412 161 941 766 301 965 254 756  92\n",
      " 784 927 253 803  80 533 120 885  36 622 343 907  57 982 735 602 431 840\n",
      " 617 671 944 544 192 142 427 704 899 259 282 475  16 164 440 816 390 729\n",
      " 306  50 268 426 674 954 754 538 194 407 116 136 753 235 334 453 542 600\n",
      "   1 688 193 104 837 632 384 418 130 200 985 520 126 279 958 897 595 762\n",
      " 137 660  18 993 497 169 998 115  51 910 848 420 454 578  67 661  12 972\n",
      " 703 322 143 968 339 122 861 537 550 409 749 608 532 489 943 984 446 630\n",
      " 346 872 499 273 815 888 199 548 341 913]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:600], :]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[600:800], :]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[800:], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X_train:  (600, 20)\n",
      "the shape of X_crossVal:  (200, 20)\n",
      "the shape of X_test:  (200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print('the shape of X_train: ', X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print('the shape of X_crossVal: ', X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print('the shape of X_test: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
